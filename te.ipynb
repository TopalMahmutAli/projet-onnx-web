{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5407e87",
   "metadata": {},
   "source": [
    "## J1 : Cours de ia predilective "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bae947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a0e2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!where pip\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd160682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1705b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e4de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data= [[1,2], [3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db35f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd010c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_data = torch.tensor(data)\n",
    "#x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7130ff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np_array = np.array(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff20ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor([2.0], requires_grad=True)\n",
    "b = torch.tensor([1.0], requires_grad=True)\n",
    "x = torch.tensor([3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517d12ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = w*x+b\n",
    "print(\"y_pred:\", y_pred.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2505d7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = torch.tensor([10.0])\n",
    "loss= (y_pred - y_true)**2\n",
    "print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e19251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Avant backward: w.grad =\", {w.grad})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f304770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194e2dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Après backward: w.grad =\", {w.grad})\n",
    "print(\"Après backward: b.grad =\", {b.grad})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006d8e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update manuel des poids\n",
    "learning_rate = 0.01\n",
    "with torch.no_grad(): #désactive le suivi des gradients pour les opérations de mise à jour w=w+alpha*x\n",
    "    w -= learning_rate * w.grad\n",
    "    b -= learning_rate * b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1050cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nouveaux paramètres: w =\", w, \", b =\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3712b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réinitialiser les gradients !! Important\n",
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(\"Après remise à zéro: w.grad =\", w.grad, \", b.grad =\", b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8eec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "percepton = nn.Linear(1, 1)\n",
    "\n",
    "#voir les poids initiaux\n",
    "print(\"poids:\", percepton.weight)\n",
    "print(\"biais : \", percepton.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f60bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#valeur de input x\n",
    "#forward\n",
    "x = torch.tensor([[3.0]]) # Shape (batch_size, features)\n",
    "print(\"input:\", x)\n",
    "y_pred = percepton(x)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123826e6",
   "metadata": {},
   "source": [
    "### théoreme centrale de limite (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3e8cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss\n",
    "y_true = torch.tensor([10.0])\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e11206",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1403dd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gradient du pois =\", percepton.weight.grad)\n",
    "print(\"Gradient du biais =\", percepton.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df8fcd1",
   "metadata": {},
   "source": [
    "###### pour la partie de en haut j'ai pas eu les meme res que le prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83262a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(percepton.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step() #met à jour les poids automatiquement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477fb445",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nouveaux poids:\", percepton.weight, \"Nouveau biais:\", percepton.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07d0da6",
   "metadata": {},
   "source": [
    "###### pour la partie de en haut j'ai pas eu les meme res que le prof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2f4c1e",
   "metadata": {},
   "source": [
    "#### On va créer des models de neuronnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6e4baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 4)\n",
    "        self.fc2 = nn.Linear(4, 3)\n",
    "        self.fc3 = nn.Linear(3, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid= nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075823d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c046b7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da7df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0, 2.0])\n",
    "y = torch.tensor([5.0])\n",
    "y_pred = model(x)\n",
    "loss = nn.MSELoss()(y_pred, y)\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f22875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21be7869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca37846",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor() #compose to tensor et normalize\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5a6039",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(training_data, batch_size=64, shuffle=True, pin_memory=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e980bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_data.classes)\n",
    "print(training_data.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dc2f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(28*28, 512), # taille image (28*28) 512\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128), # 512 - 128\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10), # 128\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7f1f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655db899",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.rand(1,28,28,device=device)\n",
    "logits=model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b059f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0040a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "pred_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b9811",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn= nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e72f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pf tips\n",
    "tuple_tets = (1,2,\"a\")\n",
    "a,b,c = tuple_tets\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fa8270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch_idx, batch_value in enumerate(dataloader): \n",
    "        X, y = batch_value\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Background pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            loss, current = loss.item(), (batch_idx+1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9ed9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0 \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader :\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss+= loss_fn(pred, y).item()\n",
    "            correct+= (pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss/= num_batches\n",
    "    correct/= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e2182",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 12\n",
    "for t in range(epochs):\n",
    "    print(f\"Epochs {t+1}\\n-------------------------------\")\n",
    "    train(training_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8ee642",
   "metadata": {},
   "source": [
    "##### pythorch tutoriel : https://docs.pytorch.org/tutorials/beginner/onnx/export_simple_model_to_onnx_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0aa2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --upgrade onnx onnxscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ce7048",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_inputs = (torch.randn(1, 1, 28, 28),)\n",
    "model.to(\"cpu\")\n",
    "onnx_program = torch.onnx.export(model, example_inputs, dynamo=True)\n",
    "onnx_program.save(\"model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fe56c9",
   "metadata": {},
   "source": [
    "##### html ccs js githubpage onnxruntime\n",
    "créer un canva, recup la taille, transfor le canva en tensor onnx coté js etc etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebbee8f",
   "metadata": {},
   "source": [
    "###### email du prof : nathan.vidal@ext.devinci.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5b2744",
   "metadata": {},
   "source": [
    "## J2 : IA pour le web\n",
    "\n",
    "* CNN (filtre + MLP ) -> new architecture\n",
    "* Dropout -> ajouter dans lancien, cest bien dans entrainment mais pas phase de test\n",
    "* Tensorboard -> faire des graphes\n",
    "* Normalization(transformation et modèle) -> si on fait normalization sur python et faut faire normalization sur js\n",
    "##### Cette première partie ce fera en autonomie, et à rendre ce soir maximum grand maximum avant 00h, (youtube : DeepIA)\n",
    "\n",
    "===============================\n",
    "##### bonus\n",
    "* Custom Dataset\n",
    "* Augmentation data (dans transform)\n",
    "* Transfer Learning (en utilisant un modèle déja fait, pour voir si ça a changé le resultat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500dc215",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0673b6b0",
   "metadata": {},
   "source": [
    "### Modele CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5757ec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "492cd0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "211fa2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize((0.1307,), (0.3081,))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b8de10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "test_data  = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac54a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(1, 6, 3, stride=1, padding=1)\n",
    "conv2 = nn.Conv2d(6, 16, 3, stride=1, padding=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e31b6296",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=3, stride=1, padding=1)   # 28x28 → 28x28\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=3, stride=1, padding=1)  # 14x14 → 14x14\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)  \n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)   \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))   \n",
    "        x = self.pool(x)               \n",
    "        x = self.relu(self.conv2(x))   \n",
    "        x = self.pool(x)              \n",
    "\n",
    "        x = torch.flatten(x, 1)        \n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64b777e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleCNN().to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46076950",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8657387",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir=\"runs/mnist_cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dc72f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for i, (X, y) in enumerate(loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 200 == 0:\n",
    "            print(f\"Epoch {epoch} | Batch {i} | Loss {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = running_loss / len(loader)\n",
    "    writer.add_scalar(\"Loss/train\", avg_loss, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8aa91541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, criterion, epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            output = model(X)\n",
    "            loss = criterion(output, y)\n",
    "            total_loss += loss.item()\n",
    "            pred = output.argmax(1)\n",
    "            correct += (pred == y).sum().item()\n",
    "\n",
    "    accuracy = correct / len(loader.dataset)\n",
    "    avg_loss = total_loss / len(loader)\n",
    "\n",
    "    writer.add_scalar(\"Loss/test\", avg_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/test\", accuracy, epoch)\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecc42eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Batch 0 | Loss 2.2997\n",
      "Epoch 1 | Batch 200 | Loss 0.2456\n",
      "Epoch 1 | Batch 400 | Loss 0.3198\n",
      "Epoch 1 | Batch 600 | Loss 0.1381\n",
      "Epoch 1 | Batch 800 | Loss 0.0643\n",
      "Test Accuracy: 97.70%\n",
      "Epoch 2 | Batch 0 | Loss 0.2030\n",
      "Epoch 2 | Batch 200 | Loss 0.1089\n",
      "Epoch 2 | Batch 400 | Loss 0.0240\n",
      "Epoch 2 | Batch 600 | Loss 0.1281\n",
      "Epoch 2 | Batch 800 | Loss 0.0460\n",
      "Test Accuracy: 98.39%\n",
      "Epoch 3 | Batch 0 | Loss 0.1168\n",
      "Epoch 3 | Batch 200 | Loss 0.1366\n",
      "Epoch 3 | Batch 400 | Loss 0.0746\n",
      "Epoch 3 | Batch 600 | Loss 0.0796\n",
      "Epoch 3 | Batch 800 | Loss 0.0499\n",
      "Test Accuracy: 98.32%\n",
      "Epoch 4 | Batch 0 | Loss 0.0522\n",
      "Epoch 4 | Batch 200 | Loss 0.0445\n",
      "Epoch 4 | Batch 400 | Loss 0.0327\n",
      "Epoch 4 | Batch 600 | Loss 0.0160\n",
      "Epoch 4 | Batch 800 | Loss 0.1167\n",
      "Test Accuracy: 98.80%\n",
      "Epoch 5 | Batch 0 | Loss 0.0674\n",
      "Epoch 5 | Batch 200 | Loss 0.0242\n",
      "Epoch 5 | Batch 400 | Loss 0.0591\n",
      "Epoch 5 | Batch 600 | Loss 0.0408\n",
      "Epoch 5 | Batch 800 | Loss 0.0376\n",
      "Test Accuracy: 98.89%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train(model, train_loader, criterion, optimizer, epoch)\n",
    "    test(model, test_loader, criterion, epoch)\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7780d372",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1211 16:30:55.913000 2920 Lib\\site-packages\\torch\\onnx\\_internal\\exporter\\_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 17 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `SimpleCNN([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `SimpleCNN([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 17).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "ONNX exporté\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "dummy = torch.randn(1, 1, 28, 28).to(device)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy,\n",
    "    \"simple_cnn.onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    opset_version=17\n",
    ")\n",
    "\n",
    "print(\"ONNX exporté\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00286dda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
