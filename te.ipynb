{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5407e87",
   "metadata": {},
   "source": [
    "# Cours de ia predilective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0bae947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40a0e2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mhmt_.000\\Documents\\Projet_IIM\\cours_ai_a4\\.venv\\Scripts\\pip.exe\n",
      "C:\\Python312\\Scripts\\pip.exe\n",
      "C:\\Python311\\Scripts\\pip.exe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\mhmt_.000\\\\Documents\\\\Projet_IIM\\\\cours_ai_a4\\\\.venv\\\\Scripts\\\\python.exe'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!where pip\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd160682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d1705b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "881e4de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data= [[1,2], [3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5db35f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cd010c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_data = torch.tensor(data)\n",
    "#x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7130ff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np_array = np.array(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ff20ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor([2.0], requires_grad=True)\n",
    "b = torch.tensor([1.0], requires_grad=True)\n",
    "x = torch.tensor([3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "517d12ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: 7.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = w*x+b\n",
    "print(\"y_pred:\", y_pred.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2505d7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 9.0\n"
     ]
    }
   ],
   "source": [
    "y_true = torch.tensor([10.0])\n",
    "loss= (y_pred - y_true)**2\n",
    "print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e19251d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avant backward: w.grad = {None}\n"
     ]
    }
   ],
   "source": [
    "print(\"Avant backward: w.grad =\", {w.grad})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f304770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "194e2dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Après backward: w.grad = {tensor([-18.])}\n",
      "Après backward: b.grad = {tensor([-6.])}\n"
     ]
    }
   ],
   "source": [
    "print(\"Après backward: w.grad =\", {w.grad})\n",
    "print(\"Après backward: b.grad =\", {b.grad})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "006d8e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update manuel des poids\n",
    "learning_rate = 0.01\n",
    "with torch.no_grad(): #désactive le suivi des gradients pour les opérations de mise à jour w=w+alpha*x\n",
    "    w -= learning_rate * w.grad\n",
    "    b -= learning_rate * b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1050cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouveaux paramètres: w = tensor([2.1800], requires_grad=True) , b = tensor([1.0600], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Nouveaux paramètres: w =\", w, \", b =\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3712b166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Après remise à zéro: w.grad = tensor([0.]) , b.grad = tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "# Réinitialiser les gradients !! Important\n",
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(\"Après remise à zéro: w.grad =\", w.grad, \", b.grad =\", b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb8eec7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poids: Parameter containing:\n",
      "tensor([[0.4073]], requires_grad=True)\n",
      "biais :  Parameter containing:\n",
      "tensor([0.8019], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "percepton = nn.Linear(1, 1)\n",
    "\n",
    "#voir les poids initiaux\n",
    "print(\"poids:\", percepton.weight)\n",
    "print(\"biais : \", percepton.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f60bb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([[3.]])\n",
      "tensor([[2.0239]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#valeur de input x\n",
    "#forward\n",
    "x = torch.tensor([[3.0]]) # Shape (batch_size, features)\n",
    "print(\"input:\", x)\n",
    "y_pred = percepton(x)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123826e6",
   "metadata": {},
   "source": [
    "### théoreme centrale de limite (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff3e8cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mhmt_.000\\Documents\\Projet_IIM\\cours_ai_a4\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:634: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "#Loss\n",
    "y_true = torch.tensor([10.0])\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56e11206",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1403dd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient du pois = tensor([[-47.8568]])\n",
      "Gradient du biais = tensor([-15.9523])\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradient du pois =\", percepton.weight.grad)\n",
    "print(\"Gradient du biais =\", percepton.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df8fcd1",
   "metadata": {},
   "source": [
    "###### pour la partie de en haut j'ai pas eu les meme res que le prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83262a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(percepton.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f024299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step() #met à jour les poids automatiquement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "477fb445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouveaux poids: Parameter containing:\n",
      "tensor([[0.8859]], requires_grad=True) Nouveau biais: Parameter containing:\n",
      "tensor([0.9614], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Nouveaux poids:\", percepton.weight, \"Nouveau biais:\", percepton.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07d0da6",
   "metadata": {},
   "source": [
    "###### pour la partie de en haut j'ai pas eu les meme res que le prof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2f4c1e",
   "metadata": {},
   "source": [
    "#### On va créer des models de neuronnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad6e4baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 4)\n",
    "        self.fc2 = nn.Linear(4, 3)\n",
    "        self.fc3 = nn.Linear(3, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid= nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "075823d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c046b7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNet(\n",
       "  (fc1): Linear(in_features=2, out_features=4, bias=True)\n",
       "  (fc2): Linear(in_features=4, out_features=3, bias=True)\n",
       "  (fc3): Linear(in_features=3, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8da7df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0, 2.0])\n",
    "y = torch.tensor([5.0])\n",
    "y_pred = model(x)\n",
    "loss = nn.MSELoss()(y_pred, y)\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85f22875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21be7869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ca37846",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d5a6039",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(training_data, batch_size=64, shuffle=True, pin_memory=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e980bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(training_data.classes)\n",
    "print(training_data.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75dc2f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(28*28, 512), # taille image (28*28) 512\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128), # 512 - 128\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10), # 128\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd7f1f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "655db899",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.rand(1,28,28,device=device)\n",
    "logits=model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8b059f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1029,  0.0463, -0.0094,  0.0880,  0.0080, -0.0595,  0.0955,  0.0784,\n",
       "         -0.1254,  0.0298]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0040a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1078, 0.1019, 0.0963, 0.1062, 0.0980, 0.0916, 0.1070, 0.1052, 0.0858,\n",
       "         0.1002]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "pred_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "410b9811",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn= nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65e72f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#pf tips\n",
    "tuple_tets = (1,2,\"a\")\n",
    "a,b,c = tuple_tets\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6fa8270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch_idx, batch_value in enumerate(dataloader): \n",
    "        X, y = batch_value\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Background pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            loss, current = loss.item(), (batch_idx+1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6a9ed9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0 \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader :\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss+= loss_fn(pred, y).item()\n",
    "            correct+= (pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss/= num_batches\n",
    "    correct/= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b5e2182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mhmt_.000\\Documents\\Projet_IIM\\cours_ai_a4\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.332087  [   64/60000]\n",
      "loss: 0.239848  [ 6464/60000]\n",
      "loss: 0.377270  [12864/60000]\n",
      "loss: 0.576638  [19264/60000]\n",
      "loss: 0.306497  [25664/60000]\n",
      "loss: 0.178224  [32064/60000]\n",
      "loss: 0.116953  [38464/60000]\n",
      "loss: 0.190186  [44864/60000]\n",
      "loss: 0.149747  [51264/60000]\n",
      "loss: 0.339604  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.271040 \n",
      "\n",
      "Epochs 2\n",
      "-------------------------------\n",
      "loss: 0.144804  [   64/60000]\n",
      "loss: 0.131037  [ 6464/60000]\n",
      "loss: 0.317378  [12864/60000]\n",
      "loss: 0.252306  [19264/60000]\n",
      "loss: 0.230124  [25664/60000]\n",
      "loss: 0.260437  [32064/60000]\n",
      "loss: 0.365137  [38464/60000]\n",
      "loss: 0.384286  [44864/60000]\n",
      "loss: 0.205964  [51264/60000]\n",
      "loss: 0.251803  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.269239 \n",
      "\n",
      "Epochs 3\n",
      "-------------------------------\n",
      "loss: 0.257635  [   64/60000]\n",
      "loss: 0.234232  [ 6464/60000]\n",
      "loss: 0.414024  [12864/60000]\n",
      "loss: 0.193989  [19264/60000]\n",
      "loss: 0.314221  [25664/60000]\n",
      "loss: 0.303291  [32064/60000]\n",
      "loss: 0.240213  [38464/60000]\n",
      "loss: 0.286276  [44864/60000]\n",
      "loss: 0.297374  [51264/60000]\n",
      "loss: 0.205625  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.267340 \n",
      "\n",
      "Epochs 4\n",
      "-------------------------------\n",
      "loss: 0.319279  [   64/60000]\n",
      "loss: 0.367317  [ 6464/60000]\n",
      "loss: 0.239099  [12864/60000]\n",
      "loss: 0.214028  [19264/60000]\n",
      "loss: 0.202518  [25664/60000]\n",
      "loss: 0.216391  [32064/60000]\n",
      "loss: 0.237229  [38464/60000]\n",
      "loss: 0.196196  [44864/60000]\n",
      "loss: 0.215083  [51264/60000]\n",
      "loss: 0.165224  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.265405 \n",
      "\n",
      "Epochs 5\n",
      "-------------------------------\n",
      "loss: 0.362291  [   64/60000]\n",
      "loss: 0.295114  [ 6464/60000]\n",
      "loss: 0.218032  [12864/60000]\n",
      "loss: 0.280288  [19264/60000]\n",
      "loss: 0.228973  [25664/60000]\n",
      "loss: 0.326003  [32064/60000]\n",
      "loss: 0.386016  [38464/60000]\n",
      "loss: 0.154210  [44864/60000]\n",
      "loss: 0.386387  [51264/60000]\n",
      "loss: 0.377957  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.263522 \n",
      "\n",
      "Epochs 6\n",
      "-------------------------------\n",
      "loss: 0.318510  [   64/60000]\n",
      "loss: 0.331675  [ 6464/60000]\n",
      "loss: 0.203509  [12864/60000]\n",
      "loss: 0.235562  [19264/60000]\n",
      "loss: 0.438361  [25664/60000]\n",
      "loss: 0.358284  [32064/60000]\n",
      "loss: 0.289362  [38464/60000]\n",
      "loss: 0.281119  [44864/60000]\n",
      "loss: 0.215675  [51264/60000]\n",
      "loss: 0.210808  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.261558 \n",
      "\n",
      "Epochs 7\n",
      "-------------------------------\n",
      "loss: 0.392245  [   64/60000]\n",
      "loss: 0.202097  [ 6464/60000]\n",
      "loss: 0.509331  [12864/60000]\n",
      "loss: 0.132506  [19264/60000]\n",
      "loss: 0.266224  [25664/60000]\n",
      "loss: 0.184261  [32064/60000]\n",
      "loss: 0.143798  [38464/60000]\n",
      "loss: 0.364449  [44864/60000]\n",
      "loss: 0.107762  [51264/60000]\n",
      "loss: 0.261193  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.259456 \n",
      "\n",
      "Epochs 8\n",
      "-------------------------------\n",
      "loss: 0.257784  [   64/60000]\n",
      "loss: 0.301149  [ 6464/60000]\n",
      "loss: 0.193923  [12864/60000]\n",
      "loss: 0.263050  [19264/60000]\n",
      "loss: 0.196210  [25664/60000]\n",
      "loss: 0.238634  [32064/60000]\n",
      "loss: 0.475889  [38464/60000]\n",
      "loss: 0.209433  [44864/60000]\n",
      "loss: 0.211064  [51264/60000]\n",
      "loss: 0.111023  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.258514 \n",
      "\n",
      "Epochs 9\n",
      "-------------------------------\n",
      "loss: 0.256650  [   64/60000]\n",
      "loss: 0.144376  [ 6464/60000]\n",
      "loss: 0.335725  [12864/60000]\n",
      "loss: 0.326412  [19264/60000]\n",
      "loss: 0.227727  [25664/60000]\n",
      "loss: 0.172681  [32064/60000]\n",
      "loss: 0.331004  [38464/60000]\n",
      "loss: 0.154579  [44864/60000]\n",
      "loss: 0.326662  [51264/60000]\n",
      "loss: 0.337701  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.256820 \n",
      "\n",
      "Epochs 10\n",
      "-------------------------------\n",
      "loss: 0.147859  [   64/60000]\n",
      "loss: 0.270847  [ 6464/60000]\n",
      "loss: 0.179532  [12864/60000]\n",
      "loss: 0.257873  [19264/60000]\n",
      "loss: 0.285060  [25664/60000]\n",
      "loss: 0.275747  [32064/60000]\n",
      "loss: 0.219886  [38464/60000]\n",
      "loss: 0.328778  [44864/60000]\n",
      "loss: 0.186420  [51264/60000]\n",
      "loss: 0.310428  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.254858 \n",
      "\n",
      "Epochs 11\n",
      "-------------------------------\n",
      "loss: 0.067549  [   64/60000]\n",
      "loss: 0.224458  [ 6464/60000]\n",
      "loss: 0.167288  [12864/60000]\n",
      "loss: 0.212589  [19264/60000]\n",
      "loss: 0.275795  [25664/60000]\n",
      "loss: 0.294523  [32064/60000]\n",
      "loss: 0.384539  [38464/60000]\n",
      "loss: 0.201755  [44864/60000]\n",
      "loss: 0.201258  [51264/60000]\n",
      "loss: 0.183759  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.253141 \n",
      "\n",
      "Epochs 12\n",
      "-------------------------------\n",
      "loss: 0.216740  [   64/60000]\n",
      "loss: 0.254888  [ 6464/60000]\n",
      "loss: 0.220900  [12864/60000]\n",
      "loss: 0.446692  [19264/60000]\n",
      "loss: 0.145571  [25664/60000]\n",
      "loss: 0.167159  [32064/60000]\n",
      "loss: 0.218565  [38464/60000]\n",
      "loss: 0.203895  [44864/60000]\n",
      "loss: 0.377488  [51264/60000]\n",
      "loss: 0.194954  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.8%, Avg loss: 0.251650 \n",
      "\n",
      "Epochs 13\n",
      "-------------------------------\n",
      "loss: 0.172036  [   64/60000]\n",
      "loss: 0.201628  [ 6464/60000]\n",
      "loss: 0.251945  [12864/60000]\n",
      "loss: 0.322699  [19264/60000]\n",
      "loss: 0.266255  [25664/60000]\n",
      "loss: 0.168149  [32064/60000]\n",
      "loss: 0.187205  [38464/60000]\n",
      "loss: 0.256438  [44864/60000]\n",
      "loss: 0.373671  [51264/60000]\n",
      "loss: 0.236045  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.9%, Avg loss: 0.249411 \n",
      "\n",
      "Epochs 14\n",
      "-------------------------------\n",
      "loss: 0.219281  [   64/60000]\n",
      "loss: 0.136823  [ 6464/60000]\n",
      "loss: 0.294637  [12864/60000]\n",
      "loss: 0.207773  [19264/60000]\n",
      "loss: 0.364016  [25664/60000]\n",
      "loss: 0.250186  [32064/60000]\n",
      "loss: 0.188388  [38464/60000]\n",
      "loss: 0.274728  [44864/60000]\n",
      "loss: 0.161686  [51264/60000]\n",
      "loss: 0.213447  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.9%, Avg loss: 0.248034 \n",
      "\n",
      "Epochs 15\n",
      "-------------------------------\n",
      "loss: 0.243028  [   64/60000]\n",
      "loss: 0.218914  [ 6464/60000]\n",
      "loss: 0.183234  [12864/60000]\n",
      "loss: 0.363447  [19264/60000]\n",
      "loss: 0.148636  [25664/60000]\n",
      "loss: 0.350685  [32064/60000]\n",
      "loss: 0.236996  [38464/60000]\n",
      "loss: 0.294025  [44864/60000]\n",
      "loss: 0.401986  [51264/60000]\n",
      "loss: 0.305585  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.246492 \n",
      "\n",
      "Epochs 16\n",
      "-------------------------------\n",
      "loss: 0.345870  [   64/60000]\n",
      "loss: 0.297009  [ 6464/60000]\n",
      "loss: 0.418844  [12864/60000]\n",
      "loss: 0.307940  [19264/60000]\n",
      "loss: 0.266756  [25664/60000]\n",
      "loss: 0.164768  [32064/60000]\n",
      "loss: 0.257796  [38464/60000]\n",
      "loss: 0.216027  [44864/60000]\n",
      "loss: 0.160704  [51264/60000]\n",
      "loss: 0.130198  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.1%, Avg loss: 0.245055 \n",
      "\n",
      "Epochs 17\n",
      "-------------------------------\n",
      "loss: 0.303463  [   64/60000]\n",
      "loss: 0.346004  [ 6464/60000]\n",
      "loss: 0.162692  [12864/60000]\n",
      "loss: 0.173773  [19264/60000]\n",
      "loss: 0.103987  [25664/60000]\n",
      "loss: 0.229484  [32064/60000]\n",
      "loss: 0.267914  [38464/60000]\n",
      "loss: 0.300869  [44864/60000]\n",
      "loss: 0.325932  [51264/60000]\n",
      "loss: 0.209457  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.243753 \n",
      "\n",
      "Epochs 18\n",
      "-------------------------------\n",
      "loss: 0.354887  [   64/60000]\n",
      "loss: 0.228177  [ 6464/60000]\n",
      "loss: 0.212296  [12864/60000]\n",
      "loss: 0.118243  [19264/60000]\n",
      "loss: 0.240247  [25664/60000]\n",
      "loss: 0.330877  [32064/60000]\n",
      "loss: 0.114908  [38464/60000]\n",
      "loss: 0.266094  [44864/60000]\n",
      "loss: 0.294270  [51264/60000]\n",
      "loss: 0.334558  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.241564 \n",
      "\n",
      "Epochs 19\n",
      "-------------------------------\n",
      "loss: 0.301757  [   64/60000]\n",
      "loss: 0.309602  [ 6464/60000]\n",
      "loss: 0.354119  [12864/60000]\n",
      "loss: 0.415113  [19264/60000]\n",
      "loss: 0.127960  [25664/60000]\n",
      "loss: 0.421536  [32064/60000]\n",
      "loss: 0.179234  [38464/60000]\n",
      "loss: 0.150490  [44864/60000]\n",
      "loss: 0.337045  [51264/60000]\n",
      "loss: 0.169991  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.240596 \n",
      "\n",
      "Epochs 20\n",
      "-------------------------------\n",
      "loss: 0.173214  [   64/60000]\n",
      "loss: 0.273990  [ 6464/60000]\n",
      "loss: 0.211143  [12864/60000]\n",
      "loss: 0.296770  [19264/60000]\n",
      "loss: 0.176589  [25664/60000]\n",
      "loss: 0.253160  [32064/60000]\n",
      "loss: 0.253168  [38464/60000]\n",
      "loss: 0.228355  [44864/60000]\n",
      "loss: 0.234166  [51264/60000]\n",
      "loss: 0.260366  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.238901 \n",
      "\n",
      "Epochs 21\n",
      "-------------------------------\n",
      "loss: 0.109602  [   64/60000]\n",
      "loss: 0.215239  [ 6464/60000]\n",
      "loss: 0.088884  [12864/60000]\n",
      "loss: 0.253864  [19264/60000]\n",
      "loss: 0.342890  [25664/60000]\n",
      "loss: 0.173936  [32064/60000]\n",
      "loss: 0.454097  [38464/60000]\n",
      "loss: 0.192948  [44864/60000]\n",
      "loss: 0.280475  [51264/60000]\n",
      "loss: 0.176891  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.237309 \n",
      "\n",
      "Epochs 22\n",
      "-------------------------------\n",
      "loss: 0.360798  [   64/60000]\n",
      "loss: 0.232928  [ 6464/60000]\n",
      "loss: 0.200421  [12864/60000]\n",
      "loss: 0.278828  [19264/60000]\n",
      "loss: 0.305362  [25664/60000]\n",
      "loss: 0.163908  [32064/60000]\n",
      "loss: 0.180492  [38464/60000]\n",
      "loss: 0.107973  [44864/60000]\n",
      "loss: 0.211742  [51264/60000]\n",
      "loss: 0.379251  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.235757 \n",
      "\n",
      "Epochs 23\n",
      "-------------------------------\n",
      "loss: 0.307695  [   64/60000]\n",
      "loss: 0.195489  [ 6464/60000]\n",
      "loss: 0.196509  [12864/60000]\n",
      "loss: 0.158202  [19264/60000]\n",
      "loss: 0.338164  [25664/60000]\n",
      "loss: 0.207752  [32064/60000]\n",
      "loss: 0.119599  [38464/60000]\n",
      "loss: 0.371173  [44864/60000]\n",
      "loss: 0.266839  [51264/60000]\n",
      "loss: 0.201139  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.234402 \n",
      "\n",
      "Epochs 24\n",
      "-------------------------------\n",
      "loss: 0.125345  [   64/60000]\n",
      "loss: 0.265845  [ 6464/60000]\n",
      "loss: 0.210729  [12864/60000]\n",
      "loss: 0.193255  [19264/60000]\n",
      "loss: 0.236677  [25664/60000]\n",
      "loss: 0.207361  [32064/60000]\n",
      "loss: 0.208246  [38464/60000]\n",
      "loss: 0.338777  [44864/60000]\n",
      "loss: 0.299181  [51264/60000]\n",
      "loss: 0.264220  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.4%, Avg loss: 0.232997 \n",
      "\n",
      "Epochs 25\n",
      "-------------------------------\n",
      "loss: 0.169565  [   64/60000]\n",
      "loss: 0.467003  [ 6464/60000]\n",
      "loss: 0.295221  [12864/60000]\n",
      "loss: 0.194412  [19264/60000]\n",
      "loss: 0.619429  [25664/60000]\n",
      "loss: 0.217139  [32064/60000]\n",
      "loss: 0.197026  [38464/60000]\n",
      "loss: 0.346583  [44864/60000]\n",
      "loss: 0.182295  [51264/60000]\n",
      "loss: 0.156595  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.230993 \n",
      "\n",
      "Epochs 26\n",
      "-------------------------------\n",
      "loss: 0.262774  [   64/60000]\n",
      "loss: 0.170083  [ 6464/60000]\n",
      "loss: 0.204032  [12864/60000]\n",
      "loss: 0.159851  [19264/60000]\n",
      "loss: 0.245373  [25664/60000]\n",
      "loss: 0.242141  [32064/60000]\n",
      "loss: 0.128018  [38464/60000]\n",
      "loss: 0.244563  [44864/60000]\n",
      "loss: 0.176023  [51264/60000]\n",
      "loss: 0.323413  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.230058 \n",
      "\n",
      "Epochs 27\n",
      "-------------------------------\n",
      "loss: 0.384592  [   64/60000]\n",
      "loss: 0.230503  [ 6464/60000]\n",
      "loss: 0.175512  [12864/60000]\n",
      "loss: 0.125440  [19264/60000]\n",
      "loss: 0.410671  [25664/60000]\n",
      "loss: 0.204162  [32064/60000]\n",
      "loss: 0.169864  [38464/60000]\n",
      "loss: 0.238414  [44864/60000]\n",
      "loss: 0.164651  [51264/60000]\n",
      "loss: 0.183587  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.228410 \n",
      "\n",
      "Epochs 28\n",
      "-------------------------------\n",
      "loss: 0.422418  [   64/60000]\n",
      "loss: 0.325646  [ 6464/60000]\n",
      "loss: 0.204701  [12864/60000]\n",
      "loss: 0.171423  [19264/60000]\n",
      "loss: 0.310100  [25664/60000]\n",
      "loss: 0.269516  [32064/60000]\n",
      "loss: 0.189043  [38464/60000]\n",
      "loss: 0.158937  [44864/60000]\n",
      "loss: 0.260503  [51264/60000]\n",
      "loss: 0.318405  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.227344 \n",
      "\n",
      "Epochs 29\n",
      "-------------------------------\n",
      "loss: 0.210514  [   64/60000]\n",
      "loss: 0.457032  [ 6464/60000]\n",
      "loss: 0.376956  [12864/60000]\n",
      "loss: 0.365553  [19264/60000]\n",
      "loss: 0.165013  [25664/60000]\n",
      "loss: 0.299752  [32064/60000]\n",
      "loss: 0.121935  [38464/60000]\n",
      "loss: 0.191609  [44864/60000]\n",
      "loss: 0.383115  [51264/60000]\n",
      "loss: 0.232324  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.6%, Avg loss: 0.225852 \n",
      "\n",
      "Epochs 30\n",
      "-------------------------------\n",
      "loss: 0.198395  [   64/60000]\n",
      "loss: 0.153579  [ 6464/60000]\n",
      "loss: 0.281382  [12864/60000]\n",
      "loss: 0.327462  [19264/60000]\n",
      "loss: 0.293329  [25664/60000]\n",
      "loss: 0.248508  [32064/60000]\n",
      "loss: 0.238229  [38464/60000]\n",
      "loss: 0.197874  [44864/60000]\n",
      "loss: 0.151849  [51264/60000]\n",
      "loss: 0.153088  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.6%, Avg loss: 0.224504 \n",
      "\n",
      "Epochs 31\n",
      "-------------------------------\n",
      "loss: 0.204930  [   64/60000]\n",
      "loss: 0.152216  [ 6464/60000]\n",
      "loss: 0.200044  [12864/60000]\n",
      "loss: 0.204371  [19264/60000]\n",
      "loss: 0.297400  [25664/60000]\n",
      "loss: 0.204658  [32064/60000]\n",
      "loss: 0.229863  [38464/60000]\n",
      "loss: 0.363094  [44864/60000]\n",
      "loss: 0.193168  [51264/60000]\n",
      "loss: 0.232879  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.7%, Avg loss: 0.222837 \n",
      "\n",
      "Epochs 32\n",
      "-------------------------------\n",
      "loss: 0.187219  [   64/60000]\n",
      "loss: 0.397072  [ 6464/60000]\n",
      "loss: 0.240320  [12864/60000]\n",
      "loss: 0.196018  [19264/60000]\n",
      "loss: 0.128400  [25664/60000]\n",
      "loss: 0.186563  [32064/60000]\n",
      "loss: 0.193157  [38464/60000]\n",
      "loss: 0.172095  [44864/60000]\n",
      "loss: 0.180586  [51264/60000]\n",
      "loss: 0.218302  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.7%, Avg loss: 0.221536 \n",
      "\n",
      "Epochs 33\n",
      "-------------------------------\n",
      "loss: 0.264273  [   64/60000]\n",
      "loss: 0.215171  [ 6464/60000]\n",
      "loss: 0.070017  [12864/60000]\n",
      "loss: 0.277847  [19264/60000]\n",
      "loss: 0.265908  [25664/60000]\n",
      "loss: 0.424357  [32064/60000]\n",
      "loss: 0.270102  [38464/60000]\n",
      "loss: 0.065572  [44864/60000]\n",
      "loss: 0.266083  [51264/60000]\n",
      "loss: 0.305751  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.7%, Avg loss: 0.220715 \n",
      "\n",
      "Epochs 34\n",
      "-------------------------------\n",
      "loss: 0.226957  [   64/60000]\n",
      "loss: 0.136777  [ 6464/60000]\n",
      "loss: 0.183287  [12864/60000]\n",
      "loss: 0.345028  [19264/60000]\n",
      "loss: 0.080601  [25664/60000]\n",
      "loss: 0.189399  [32064/60000]\n",
      "loss: 0.269036  [38464/60000]\n",
      "loss: 0.132427  [44864/60000]\n",
      "loss: 0.138316  [51264/60000]\n",
      "loss: 0.310596  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.7%, Avg loss: 0.219084 \n",
      "\n",
      "Epochs 35\n",
      "-------------------------------\n",
      "loss: 0.139373  [   64/60000]\n",
      "loss: 0.185551  [ 6464/60000]\n",
      "loss: 0.238732  [12864/60000]\n",
      "loss: 0.199913  [19264/60000]\n",
      "loss: 0.275094  [25664/60000]\n",
      "loss: 0.190263  [32064/60000]\n",
      "loss: 0.233913  [38464/60000]\n",
      "loss: 0.180469  [44864/60000]\n",
      "loss: 0.169400  [51264/60000]\n",
      "loss: 0.190070  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.7%, Avg loss: 0.218155 \n",
      "\n",
      "Epochs 36\n",
      "-------------------------------\n",
      "loss: 0.134802  [   64/60000]\n",
      "loss: 0.196714  [ 6464/60000]\n",
      "loss: 0.143098  [12864/60000]\n",
      "loss: 0.171840  [19264/60000]\n",
      "loss: 0.212487  [25664/60000]\n",
      "loss: 0.141816  [32064/60000]\n",
      "loss: 0.163247  [38464/60000]\n",
      "loss: 0.206513  [44864/60000]\n",
      "loss: 0.276505  [51264/60000]\n",
      "loss: 0.194052  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.216868 \n",
      "\n",
      "Epochs 37\n",
      "-------------------------------\n",
      "loss: 0.194389  [   64/60000]\n",
      "loss: 0.245490  [ 6464/60000]\n",
      "loss: 0.443316  [12864/60000]\n",
      "loss: 0.404215  [19264/60000]\n",
      "loss: 0.143539  [25664/60000]\n",
      "loss: 0.136324  [32064/60000]\n",
      "loss: 0.135841  [38464/60000]\n",
      "loss: 0.209428  [44864/60000]\n",
      "loss: 0.235976  [51264/60000]\n",
      "loss: 0.224116  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.215436 \n",
      "\n",
      "Epochs 38\n",
      "-------------------------------\n",
      "loss: 0.193069  [   64/60000]\n",
      "loss: 0.167171  [ 6464/60000]\n",
      "loss: 0.173048  [12864/60000]\n",
      "loss: 0.279928  [19264/60000]\n",
      "loss: 0.320635  [25664/60000]\n",
      "loss: 0.220802  [32064/60000]\n",
      "loss: 0.294876  [38464/60000]\n",
      "loss: 0.104759  [44864/60000]\n",
      "loss: 0.195395  [51264/60000]\n",
      "loss: 0.264246  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.214457 \n",
      "\n",
      "Epochs 39\n",
      "-------------------------------\n",
      "loss: 0.165091  [   64/60000]\n",
      "loss: 0.123273  [ 6464/60000]\n",
      "loss: 0.160945  [12864/60000]\n",
      "loss: 0.135815  [19264/60000]\n",
      "loss: 0.186108  [25664/60000]\n",
      "loss: 0.168436  [32064/60000]\n",
      "loss: 0.193433  [38464/60000]\n",
      "loss: 0.123490  [44864/60000]\n",
      "loss: 0.461783  [51264/60000]\n",
      "loss: 0.303809  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.212748 \n",
      "\n",
      "Epochs 40\n",
      "-------------------------------\n",
      "loss: 0.268497  [   64/60000]\n",
      "loss: 0.224601  [ 6464/60000]\n",
      "loss: 0.088504  [12864/60000]\n",
      "loss: 0.124936  [19264/60000]\n",
      "loss: 0.492049  [25664/60000]\n",
      "loss: 0.313229  [32064/60000]\n",
      "loss: 0.190097  [38464/60000]\n",
      "loss: 0.197923  [44864/60000]\n",
      "loss: 0.156494  [51264/60000]\n",
      "loss: 0.200528  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.211660 \n",
      "\n",
      "Epochs 41\n",
      "-------------------------------\n",
      "loss: 0.287912  [   64/60000]\n",
      "loss: 0.187147  [ 6464/60000]\n",
      "loss: 0.255040  [12864/60000]\n",
      "loss: 0.083959  [19264/60000]\n",
      "loss: 0.184843  [25664/60000]\n",
      "loss: 0.167647  [32064/60000]\n",
      "loss: 0.329872  [38464/60000]\n",
      "loss: 0.124573  [44864/60000]\n",
      "loss: 0.204120  [51264/60000]\n",
      "loss: 0.185140  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.210378 \n",
      "\n",
      "Epochs 42\n",
      "-------------------------------\n",
      "loss: 0.124803  [   64/60000]\n",
      "loss: 0.229064  [ 6464/60000]\n",
      "loss: 0.092744  [12864/60000]\n",
      "loss: 0.198211  [19264/60000]\n",
      "loss: 0.166138  [25664/60000]\n",
      "loss: 0.307099  [32064/60000]\n",
      "loss: 0.150223  [38464/60000]\n",
      "loss: 0.488283  [44864/60000]\n",
      "loss: 0.204628  [51264/60000]\n",
      "loss: 0.090386  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.209188 \n",
      "\n",
      "Epochs 43\n",
      "-------------------------------\n",
      "loss: 0.197809  [   64/60000]\n",
      "loss: 0.111487  [ 6464/60000]\n",
      "loss: 0.165459  [12864/60000]\n",
      "loss: 0.084846  [19264/60000]\n",
      "loss: 0.257056  [25664/60000]\n",
      "loss: 0.127609  [32064/60000]\n",
      "loss: 0.194608  [38464/60000]\n",
      "loss: 0.284450  [44864/60000]\n",
      "loss: 0.251075  [51264/60000]\n",
      "loss: 0.295904  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.208093 \n",
      "\n",
      "Epochs 44\n",
      "-------------------------------\n",
      "loss: 0.333258  [   64/60000]\n",
      "loss: 0.172987  [ 6464/60000]\n",
      "loss: 0.122040  [12864/60000]\n",
      "loss: 0.068310  [19264/60000]\n",
      "loss: 0.197120  [25664/60000]\n",
      "loss: 0.156589  [32064/60000]\n",
      "loss: 0.385117  [38464/60000]\n",
      "loss: 0.193161  [44864/60000]\n",
      "loss: 0.293112  [51264/60000]\n",
      "loss: 0.180722  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.206797 \n",
      "\n",
      "Epochs 45\n",
      "-------------------------------\n",
      "loss: 0.260429  [   64/60000]\n",
      "loss: 0.193573  [ 6464/60000]\n",
      "loss: 0.191585  [12864/60000]\n",
      "loss: 0.126102  [19264/60000]\n",
      "loss: 0.162249  [25664/60000]\n",
      "loss: 0.196553  [32064/60000]\n",
      "loss: 0.147227  [38464/60000]\n",
      "loss: 0.180974  [44864/60000]\n",
      "loss: 0.353323  [51264/60000]\n",
      "loss: 0.241711  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.205846 \n",
      "\n",
      "Epochs 46\n",
      "-------------------------------\n",
      "loss: 0.137256  [   64/60000]\n",
      "loss: 0.205296  [ 6464/60000]\n",
      "loss: 0.211976  [12864/60000]\n",
      "loss: 0.245732  [19264/60000]\n",
      "loss: 0.267722  [25664/60000]\n",
      "loss: 0.189655  [32064/60000]\n",
      "loss: 0.181511  [38464/60000]\n",
      "loss: 0.119437  [44864/60000]\n",
      "loss: 0.190330  [51264/60000]\n",
      "loss: 0.096530  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.204478 \n",
      "\n",
      "Epochs 47\n",
      "-------------------------------\n",
      "loss: 0.167255  [   64/60000]\n",
      "loss: 0.101658  [ 6464/60000]\n",
      "loss: 0.215210  [12864/60000]\n",
      "loss: 0.229078  [19264/60000]\n",
      "loss: 0.252540  [25664/60000]\n",
      "loss: 0.111995  [32064/60000]\n",
      "loss: 0.149235  [38464/60000]\n",
      "loss: 0.177162  [44864/60000]\n",
      "loss: 0.130101  [51264/60000]\n",
      "loss: 0.128210  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.203472 \n",
      "\n",
      "Epochs 48\n",
      "-------------------------------\n",
      "loss: 0.354332  [   64/60000]\n",
      "loss: 0.242692  [ 6464/60000]\n",
      "loss: 0.132578  [12864/60000]\n",
      "loss: 0.229637  [19264/60000]\n",
      "loss: 0.120725  [25664/60000]\n",
      "loss: 0.135766  [32064/60000]\n",
      "loss: 0.180070  [38464/60000]\n",
      "loss: 0.159035  [44864/60000]\n",
      "loss: 0.281122  [51264/60000]\n",
      "loss: 0.220145  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.202380 \n",
      "\n",
      "Epochs 49\n",
      "-------------------------------\n",
      "loss: 0.285444  [   64/60000]\n",
      "loss: 0.088131  [ 6464/60000]\n",
      "loss: 0.208661  [12864/60000]\n",
      "loss: 0.126625  [19264/60000]\n",
      "loss: 0.177191  [25664/60000]\n",
      "loss: 0.239836  [32064/60000]\n",
      "loss: 0.247462  [38464/60000]\n",
      "loss: 0.353390  [44864/60000]\n",
      "loss: 0.195930  [51264/60000]\n",
      "loss: 0.326179  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.201006 \n",
      "\n",
      "Epochs 50\n",
      "-------------------------------\n",
      "loss: 0.193825  [   64/60000]\n",
      "loss: 0.291216  [ 6464/60000]\n",
      "loss: 0.144245  [12864/60000]\n",
      "loss: 0.235238  [19264/60000]\n",
      "loss: 0.203830  [25664/60000]\n",
      "loss: 0.117572  [32064/60000]\n",
      "loss: 0.236194  [38464/60000]\n",
      "loss: 0.294121  [44864/60000]\n",
      "loss: 0.088533  [51264/60000]\n",
      "loss: 0.167285  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.199931 \n",
      "\n",
      "Epochs 51\n",
      "-------------------------------\n",
      "loss: 0.079574  [   64/60000]\n",
      "loss: 0.222134  [ 6464/60000]\n",
      "loss: 0.217920  [12864/60000]\n",
      "loss: 0.166118  [19264/60000]\n",
      "loss: 0.230850  [25664/60000]\n",
      "loss: 0.228609  [32064/60000]\n",
      "loss: 0.367941  [38464/60000]\n",
      "loss: 0.309484  [44864/60000]\n",
      "loss: 0.079325  [51264/60000]\n",
      "loss: 0.222259  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.198774 \n",
      "\n",
      "Epochs 52\n",
      "-------------------------------\n",
      "loss: 0.212192  [   64/60000]\n",
      "loss: 0.313465  [ 6464/60000]\n",
      "loss: 0.353624  [12864/60000]\n",
      "loss: 0.198273  [19264/60000]\n",
      "loss: 0.228998  [25664/60000]\n",
      "loss: 0.229127  [32064/60000]\n",
      "loss: 0.125198  [38464/60000]\n",
      "loss: 0.091790  [44864/60000]\n",
      "loss: 0.079966  [51264/60000]\n",
      "loss: 0.274589  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.3%, Avg loss: 0.197811 \n",
      "\n",
      "Epochs 53\n",
      "-------------------------------\n",
      "loss: 0.160407  [   64/60000]\n",
      "loss: 0.247480  [ 6464/60000]\n",
      "loss: 0.176851  [12864/60000]\n",
      "loss: 0.349473  [19264/60000]\n",
      "loss: 0.144702  [25664/60000]\n",
      "loss: 0.216564  [32064/60000]\n",
      "loss: 0.301240  [38464/60000]\n",
      "loss: 0.460516  [44864/60000]\n",
      "loss: 0.127432  [51264/60000]\n",
      "loss: 0.213780  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.197290 \n",
      "\n",
      "Epochs 54\n",
      "-------------------------------\n",
      "loss: 0.196407  [   64/60000]\n",
      "loss: 0.189750  [ 6464/60000]\n",
      "loss: 0.121344  [12864/60000]\n",
      "loss: 0.095987  [19264/60000]\n",
      "loss: 0.190200  [25664/60000]\n",
      "loss: 0.072398  [32064/60000]\n",
      "loss: 0.195966  [38464/60000]\n",
      "loss: 0.289202  [44864/60000]\n",
      "loss: 0.144158  [51264/60000]\n",
      "loss: 0.145148  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.3%, Avg loss: 0.195604 \n",
      "\n",
      "Epochs 55\n",
      "-------------------------------\n",
      "loss: 0.181168  [   64/60000]\n",
      "loss: 0.168823  [ 6464/60000]\n",
      "loss: 0.182573  [12864/60000]\n",
      "loss: 0.341257  [19264/60000]\n",
      "loss: 0.136854  [25664/60000]\n",
      "loss: 0.204509  [32064/60000]\n",
      "loss: 0.302258  [38464/60000]\n",
      "loss: 0.259401  [44864/60000]\n",
      "loss: 0.092455  [51264/60000]\n",
      "loss: 0.319440  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.194291 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 55\n",
    "for t in range(epochs):\n",
    "    print(f\"Epochs {t+1}\\n-------------------------------\")\n",
    "    train(training_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8ee642",
   "metadata": {},
   "source": [
    "##### pythorch tutoriel : https://docs.pytorch.org/tutorials/beginner/onnx/export_simple_model_to_onnx_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d0aa2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --upgrade onnx onnxscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a6ce7048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `NeuralNetwork([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `NeuralNetwork([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n"
     ]
    }
   ],
   "source": [
    "example_inputs = (torch.randn(1, 1, 28, 28),)\n",
    "model.to(\"cpu\")\n",
    "onnx_program = torch.onnx.export(model, example_inputs, dynamo=True)\n",
    "onnx_program.save(\"model3.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fe56c9",
   "metadata": {},
   "source": [
    "##### html ccs js githubpage onnxruntime\n",
    "créer un canva, recup la taille, transfor le canva en tensor onnx coté js etc etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebbee8f",
   "metadata": {},
   "source": [
    "###### email du prof : nathan.vidal@ext.devinci.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5b2744",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
